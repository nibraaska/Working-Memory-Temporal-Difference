{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_states = [1, 2]\n",
    "size_of_maze = 4\n",
    "episodes = 100000\n",
    "\n",
    "discount = 0.9\n",
    "alpha = 0.01\n",
    "e_soft = 0.01\n",
    "\n",
    "n = 256\n",
    "\n",
    "inputs = n\n",
    "ouputs = 1\n",
    "\n",
    "reward_bad = -1\n",
    "reward_good = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrr(length, normalized=False):\n",
    "    if normalized:\n",
    "        x = np.random.uniform(-np.pi,np.pi,int((length-1)/2))\n",
    "        if length % 2:\n",
    "            x = np.real(np.fft.ifft(np.concatenate([np.ones(1), np.exp(1j*x), np.exp(-1j*x[::-1])])))\n",
    "        else:\n",
    "            x = np.real(np.fft.ifft(np.concatenate([np.ones(1), np.exp(1j*x), np.ones(1), np.exp(-1j*x[::-1])])))\n",
    "    else:\n",
    "        x = np.random.normal(0.0, 1.0/np.sqrt(length), length)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_hrrs = np.zeros([size_of_maze, n])\n",
    "for x in range(size_of_maze):\n",
    "    state_hrrs[x] = hrr(n, True)\n",
    "\n",
    "identity_hrr = np.zeros(n)\n",
    "identity_hrr[0] = 1\n",
    "\n",
    "color_hrrs_internal = np.zeros([len(goal_states), n])\n",
    "color_hrrs_external = np.zeros([len(goal_states), n])\n",
    "for x in range(len(goal_states)):\n",
    "    color_hrrs_internal[x] = hrr(n, True)\n",
    "    color_hrrs_external[x] = hrr(n, True)\n",
    "possible_signals = np.vstack((identity_hrr, color_hrrs_external))\n",
    "possible_wm = np.vstack((identity_hrr, color_hrrs_internal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(x, y):\n",
    "    return np.real(np.fft.ifft(np.fft.fft(x)*np.fft.fft(y)))\n",
    "\n",
    "def preconvolve():\n",
    "    preconvolved_matrix = np.zeros([possible_signals.size, possible_wm.size, size_of_maze, n])\n",
    "    for x in range(len(possible_signals)):\n",
    "        for y in range(len(possible_wm)):\n",
    "            for z in range(size_of_maze):\n",
    "                preconvolved_matrix[x][y][z] = convolve(possible_signals[x], convolve(possible_wm[y], state_hrrs[z]))\n",
    "    return preconvolved_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state_left, state_right, wm, color, signal, rand_on):\n",
    "    # Calculates the value of each possible decision\n",
    "    # Value of stepping left with signal and with signal and wm\n",
    "    value_left_state_x = nn.feedforward(preconvolved_matrix[signal][0][state_left])\n",
    "    value_left_state_wm = nn.feedforward(preconvolved_matrix[signal][wm][state_left])\n",
    "    \n",
    "    # Value of stepping right with signal and with signal and wm\n",
    "    value_right_state_x = nn.feedforward(preconvolved_matrix[signal][0][state_right])\n",
    "    value_right_state_wm = nn.feedforward(preconvolved_matrix[signal][wm][state_right])\n",
    "    \n",
    "    # Random move\n",
    "    if((np.random.random() < e_soft) and (rand_on == 1)):\n",
    "        return np.random.choice([-1, 1]), wm\n",
    "    \n",
    "    # Properly sets signal to the repective internal value\n",
    "    if(not (np.array_equal(signal, identity_hrr))):\n",
    "        internal_color = color + 1\n",
    "    \n",
    "    # Calculates max value\n",
    "    max_value = max(value_left_state_x, value_left_state_wm, value_right_state_x, value_right_state_wm)\n",
    "    \n",
    "    # Figures out what to return\n",
    "    if(max_value == value_left_state_x):\n",
    "        return -1, internal_color\n",
    "    elif(max_value == value_left_state_wm):\n",
    "        return -1, wm\n",
    "    elif(max_value == value_right_state_x):\n",
    "        return 1, internal_color\n",
    "    elif(max_value == value_right_state_wm):\n",
    "        return 1, wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputs, outputs, discount, alpha):\n",
    "        self.discount = discount\n",
    "        self.alpha = alpha\n",
    "        self.input = inputs\n",
    "        self.output = outputs\n",
    "        self.weights = hrr(n, True)\n",
    "        self.bias = 0\n",
    "        \n",
    "    def feedforward(self, X):\n",
    "        self.output = np.dot(self.weights, X) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self, state_prime_hrr, state_hrr, y):\n",
    "        if(y == reward_good):\n",
    "            self.error = reward_good - self.feedforward(state_hrr)\n",
    "            self.weights = np.add(self.weights, (self.alpha * self.error * state_hrr))\n",
    "        else:\n",
    "            self.error = (reward_bad + self.discount * self.feedforward(state_hrr)) - self.feedforward(state_prime_hrr)\n",
    "            self.weights = np.add(self.weights, (self.alpha * self.error * state_prime_hrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preconvolved_matrix = preconvolve()\n",
    "nn = NeuralNetwork(n, 1, discount, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state = random.randint(0, size_of_maze - 1)\n",
    "state_prime = state\n",
    "rand_color = np.random.choice(len(goal_states))\n",
    "goal_state = goal_states[rand_color]\n",
    "signal = rand_color + 1\n",
    "old_signa = signal\n",
    "for x in range(episodes):\n",
    "        wm = 0\n",
    "        while(state != goal_state):\n",
    "            old_wm = wm\n",
    "            color = rand_color\n",
    "            if(state == 0):\n",
    "                decision, wm = policy(size_of_maze - 1, 1, wm, color, signal, 1)\n",
    "                if(decision == -1):\n",
    "                    state_prime = state\n",
    "                    state = size_of_maze - 1\n",
    "                else:\n",
    "                    state_prime = state\n",
    "                    state = state + decision\n",
    "            elif(state == size_of_maze - 1):\n",
    "                decision, wm = policy(state - 1, 0, wm, color, signal, 1)\n",
    "                if(decision == -1):\n",
    "                    state_prime = state\n",
    "                    state = state + decision\n",
    "                else:\n",
    "                    state_prime = state\n",
    "                    state = 0\n",
    "            else:\n",
    "                decision, wm = policy(state - 1, state + 1, wm, color, signal, 1)\n",
    "                state_prime = state\n",
    "                state = state + decision\n",
    "            nn.backprop(preconvolved_matrix[old_signal][old_wm][state_prime], preconvolved_matrix[signal][wm][state], reward_bad)\n",
    "            old_signal = signal\n",
    "            signal = 0\n",
    "        nn.backprop(preconvolved_matrix[old_signal][old_wm][state_prime], preconvolved_matrix[signal][wm][state], reward_good)\n",
    "        state = random.randint(0, size_of_maze - 1)\n",
    "        state_prime = state\n",
    "        rand_color = np.random.choice(len(goal_states))\n",
    "        goal_state = goal_states[rand_color]\n",
    "        signal = rand_color + 1\n",
    "        old_signa = signal\n",
    "        if((x+1)%10000 == 0):\n",
    "            print(\"Episode\", x+1, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "position = np.arange(size_of_maze)\n",
    "value = np.zeros(size_of_maze)\n",
    "for x in range (np.size(possible_signals, 0)):\n",
    "    for y in range (np.size(possible_wm, 0)):\n",
    "        for z in range (size_of_maze):\n",
    "            value[z] = nn.feedforward(convolve(state_hrrs[z], (convolve(possible_signals[x], possible_wm[y]))))\n",
    "        plt.plot(position, value) \n",
    "        print(np.amax(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.arange(size_of_maze)\n",
    "value = np.zeros(size_of_maze)\n",
    "for z in range (size_of_maze):\n",
    "    value[z] = nn.feedforward(convolve(state_hrrs[z], possible_wm[1]))\n",
    "plt.plot(position, value) \n",
    "print(np.amax(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.arange(size_of_maze)\n",
    "value = np.zeros(size_of_maze)\n",
    "for z in range (size_of_maze):\n",
    "    value[z] = nn.feedforward(convolve(state_hrrs[z], possible_wm[2]))\n",
    "plt.plot(position, value) \n",
    "print(np.amax(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

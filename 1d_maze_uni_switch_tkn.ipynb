{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_states = [1, 3]\n",
    "size_of_maze = 4\n",
    "episodes = 10000\n",
    "\n",
    "discount = 0.5\n",
    "alpha = 0.01\n",
    "e_soft = 0.01\n",
    "\n",
    "n = 1024\n",
    "\n",
    "inputs = n\n",
    "ouputs = 1\n",
    "\n",
    "reward_bad = 0\n",
    "reward_good = 1\n",
    "\n",
    "threshold = -0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrr(length, normalized=False):\n",
    "    if normalized:\n",
    "        x = np.random.uniform(-np.pi,np.pi,int((length-1)/2))\n",
    "        if length % 2:\n",
    "            x = np.real(np.fft.ifft(np.concatenate([np.ones(1), np.exp(1j*x), np.exp(-1j*x[::-1])])))\n",
    "        else:\n",
    "            x = np.real(np.fft.ifft(np.concatenate([np.ones(1), np.exp(1j*x), np.ones(1), np.exp(-1j*x[::-1])])))\n",
    "    else:\n",
    "        x = np.random.normal(0.0, 1.0/np.sqrt(length), length)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_hrrs = np.zeros([size_of_maze, n])\n",
    "for x in range(size_of_maze):\n",
    "    state_hrrs[x] = hrr(n, True)\n",
    "    \n",
    "color_hrrs_internal = np.zeros([len(goal_states), n])\n",
    "for x in range(len(goal_states)):\n",
    "    color_hrrs_internal[x] = hrr(n, True)\n",
    "possible_wm = color_hrrs_internal\n",
    "\n",
    "reward_tkn = hrr(n, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(x, y):\n",
    "    return np.real(np.fft.ifft(np.fft.fft(x)*np.fft.fft(y)))\n",
    "def preconvolve():\n",
    "    preconvolved_matrix = np.zeros([possible_wm.size, size_of_maze, n])\n",
    "    for x in range(len(possible_wm)):\n",
    "        for y in range(size_of_maze):\n",
    "            preconvolved_matrix[x][y] = convolve(possible_wm[x], state_hrrs[y])\n",
    "    return preconvolved_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_mov(state_left, state_right, wm, rand_on):\n",
    "    value_left_state_wm = nn.feedforward(preconvolved_matrix[wm][state_left])\n",
    "    value_right_state_wm = nn.feedforward(preconvolved_matrix[wm][state_right])\n",
    "    if((np.random.random() < e_soft) and (rand_on == 1)):\n",
    "        return np.random.choice([-1, 1])\n",
    "    max_value = max(value_left_state_wm, value_right_state_wm)\n",
    "    if(max_value == value_left_state_wm):\n",
    "        return -1\n",
    "    elif(max_value == value_right_state_wm):\n",
    "        return 1\n",
    "    \n",
    "def policy_switch(state, wm, color, error):\n",
    "    return (wm + 1)%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputs, outputs, discount, alpha):\n",
    "        self.discount = discount\n",
    "        self.alpha = alpha\n",
    "        self.input = inputs\n",
    "        self.output = outputs\n",
    "        self.weights = hrr(n, True)\n",
    "        self.bias = 0\n",
    "    def feedforward(self, X):\n",
    "        self.output = np.dot(self.weights, X) + self.bias\n",
    "        return self.output\n",
    "    def backprop(self, state_prime_hrr, state_hrr, wm, y):\n",
    "        if(y == reward_good):\n",
    "            self.error = reward_good - self.feedforward(state_hrr)\n",
    "            self.weights = np.add(self.weights, (self.alpha * self.error * state_hrr))\n",
    "        else:\n",
    "            self.error = (reward_bad + self.discount * self.feedforward(state_hrr)) - self.feedforward(state_prime_hrr)\n",
    "            if self.error < threshold:\n",
    "                wm = policy_switch(state, wm, color, self.error)\n",
    "                return wm\n",
    "            self.weights = np.add(self.weights, (self.alpha * self.error * state_prime_hrr))\n",
    "        return wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preconvolved_matrix = preconvolve()\n",
    "nn = NeuralNetwork(n, 1, discount, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state = random.randint(0, size_of_maze - 1)\n",
    "state_prime = state\n",
    "steps = 0\n",
    "count = 0\n",
    "wm = 0\n",
    "for x in range(episodes):\n",
    "        steps = 0\n",
    "        count += 1\n",
    "        if count <= 10:\n",
    "            if count == 1:\n",
    "                goal_state = goal_states[0]\n",
    "            pass\n",
    "        elif count > 10 and count < 20:\n",
    "            if count == 11:\n",
    "                goal_state = goal_states[1]\n",
    "            pass\n",
    "        elif count >= 20:\n",
    "            count = 0\n",
    "        while(steps<30):\n",
    "            steps += 1\n",
    "            if(state == 0):\n",
    "                decision = policy_mov(size_of_maze - 1, 1, wm, 1)\n",
    "                if(decision == -1):\n",
    "                    state_prime = state\n",
    "                    state = size_of_maze - 1\n",
    "                else:\n",
    "                    state_prime = state\n",
    "                    state = state + decision\n",
    "            elif(state == size_of_maze - 1):\n",
    "                decision = policy_mov(state - 1, 0, wm, 1)\n",
    "                if(decision == -1):\n",
    "                    state_prime = state\n",
    "                    state = state + decision\n",
    "                else:\n",
    "                    state_prime = state\n",
    "                    state = 0\n",
    "            else:\n",
    "                decision = policy_mov(state - 1, state + 1, wm, 1)\n",
    "                state_prime = state\n",
    "                state = state + decision\n",
    "            old_wm = wm\n",
    "            wm = nn.backprop(preconvolved_matrix[old_wm][state_prime], preconvolved_matrix[wm][state], wm, reward_bad)\n",
    "            if state == goal_state:\n",
    "                nn.backprop(preconvolved_matrix[old_wm][state_prime], convolve(reward_tkn, preconvolved_matrix[wm][state]), wm, reward_good)\n",
    "                break\n",
    "        state = random.randint(0, size_of_maze - 1)\n",
    "        state_prime = state\n",
    "        print(\"Episode\", x+1, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "position = np.arange(size_of_maze)\n",
    "value = np.zeros(size_of_maze)\n",
    "for z in range (size_of_maze):\n",
    "    if z == 1:\n",
    "        value[z] = nn.feedforward(convolve(reward_tkn, preconvolved_matrix[0][z]))\n",
    "    else:\n",
    "        value[z] = nn.feedforward(preconvolved_matrix[0][z])\n",
    "plt.plot(position, value)\n",
    "print(np.amax(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.arange(size_of_maze)\n",
    "value = np.zeros(size_of_maze)\n",
    "for z in range (size_of_maze):\n",
    "    if z == 3:\n",
    "        value[z] = nn.feedforward(convolve(reward_tkn, preconvolved_matrix[0][z]))\n",
    "    else:\n",
    "        value[z] = nn.feedforward(preconvolved_matrix[0][z])\n",
    "plt.plot(position, value) \n",
    "print(np.amax(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
